{
  "sectionId": "sec-data-flow",
  "blocks": [
    {
      "type": "heading",
      "text": "How Data Gets From Disk to CPU",
      "blockIndex": 0
    },
    {
      "type": "paragraph",
      "text": "When you open a file, a complex chain of events happens in milliseconds. Your application asks the operating system (the software that manages your computer's hardware — like Windows, macOS, or Linux), which passes the request through several layers down to the SSD hardware, and back up again.",
      "blockIndex": 1
    },
    {
      "type": "analogy",
      "text": "Analogy: The I/O Path Is Like a Restaurant Order. You (the application) tell the waiter (the OS) what you want. The waiter writes it on an order slip (NVMe command) and puts it on the kitchen counter (submission queue). The chef (SSD controller) picks it up, retrieves the ingredients from the pantry (NAND flash), plates the dish, and puts it on the pickup counter (completion queue). The waiter delivers it to your table.",
      "blockIndex": 2
    },
    {
      "type": "paragraph",
      "text": "But how does the CPU actually &ldquo;talk to&rdquo; the SSD? Hardware devices have tiny built-in memory locations called registers — each one controls a specific function (like &ldquo;start processing commands&rdquo; or &ldquo;report your status&rdquo;). The CPU accesses these registers through a technique called Memory-Mapped I/O (MMIO): the SSD's registers are assigned normal memory addresses, so the CPU can read or write them just like reading or writing RAM.",
      "blockIndex": 3
    },
    {
      "type": "paragraph",
      "text": "This is exactly how NVMe works: the SSD's control registers are mapped into a region of memory called BAR0 (Base Address Register 0). When the CPU writes to an address in BAR0, the SSD receives it as a command. We'll explore this in detail in Lesson 6.",
      "blockIndex": 4
    },
    {
      "type": "info",
      "text": "Why This Matters: Understanding this data flow is the foundation for everything that follows. When we talk about queues, doorbells, DMA, and interrupts in later lessons, you'll know exactly where they fit in this pipeline. The entire NVMe protocol is designed to make this flow as fast as possible.",
      "blockIndex": 5
    },
    {
      "type": "reveal",
      "text": "Knowledge check: Why is it elegant that the CPU 'doesn't know' it's talking to an SSD when using Memory-Mapped I/O? What would the alternative look like, and why would it be worse? The answer: In MMIO, the SSD's control registers are mapped to normal memory addresses. The CPU reads and writes these addresses as if they were RAM, but the hardware silently routes those accesses to the SSD's registers via PCIe. This is elegant because the CPU uses the same load/store instructions it already knows — no special I/O instructions needed. The alternative (port-mapped I/O using IN/OUT instructions) requires separate address spaces, special privilege levels, and can't leverage the CPU's existing memory infrastructure like caches and TLBs. MMIO also scales better: any number of devices can be mapped into the vast 64-bit address space, whereas I/O ports are limited to a 16-bit address range (65,536 ports total).",
      "requiresReveal": true,
      "blockIndex": 6
    }
  ]
}